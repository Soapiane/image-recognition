{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "394d86b8",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c89500f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "test\n",
      "train\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Opening files\n",
    "import os\n",
    "\n",
    "# Data preprocessing\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Model evaluations\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import os\n",
    "\n",
    "def print_directories(path='.'):\n",
    " for name in os.listdir(path):\n",
    "     if os.path.isdir(os.path.join(path, name)):\n",
    "         print(name)\n",
    "\n",
    "print_directories()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6213c5f3",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da80e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    threshold = 128\n",
    "    # Parcourir tout les sous-dossiers\n",
    "    for sous_dossier in os.listdir(folder):\n",
    "        sous_dossier_path = os.path.join(folder, sous_dossier)\n",
    "        if os.path.isdir(sous_dossier_path):\n",
    "            # For each file inside of the sub-directory\n",
    "            for file in os.listdir(sous_dossier_path):\n",
    "                # Créer le chemin vers le fichier\n",
    "                file_path = os.path.join(sous_dossier_path, file)\n",
    "                # Convertir l'image en niveaux de gris\n",
    "                image = Image.open(file_path).convert('L')\n",
    "                # Binariser l'image selon le seuil\n",
    "                image = np.array(image)\n",
    "                image = np.where(image > threshold, 0, 1)  # 0 pour blanc, 1 pour noir\n",
    "                # Transformer l'image en un vecteur\n",
    "                image = image.flatten()\n",
    "                # Ajouter l'image a images[]\n",
    "                images.append(image)\n",
    "                # Ajouter le sous-dossier a labels[]\n",
    "                labels.append(sous_dossier)\n",
    "    # Instancier le LabelEncoder\n",
    "    # Turn categorical data into numerical values\n",
    "    le = LabelEncoder()\n",
    "    # Ajuster le LabelEncoder et transformer les labels\n",
    "    labels = le.fit_transform(labels)\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c573f7e",
   "metadata": {},
   "source": [
    "# Divide the dataset into testing data and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a3d14c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "X, y = preprocess_images('train')\n",
    "\n",
    "# Diviser les données en un ensemble d'entraînement et un ensemble de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82041fcb",
   "metadata": {},
   "source": [
    "# Prediction using decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3f9b79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Decision Tree: 0.5726495726495726\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary library for Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate the model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make a prediction\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Accuracy Decision Tree: {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915dba9c",
   "metadata": {},
   "source": [
    "# Prediction using random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48038e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random forests: 0.7264957264957265\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary library for random forests classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instancier le modèle\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Entraîner le modèle\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Faire une prédiction\n",
    "y_pred = model.predict(X_test)\n",
    "model2 = model\n",
    "# Évaluer le modèle\n",
    "print(f'Accuracy Random forests: {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796f705e",
   "metadata": {},
   "source": [
    "# Preduction using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9104b811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy XGB: 0.7350427350427351\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary library for XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "# Instancier le modèle\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Entraîner le modèle\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Faire une prédiction\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluer le modèle\n",
    "print(f'Accuracy XGB: {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9135f904",
   "metadata": {},
   "source": [
    "# Predict using CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89973d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement des images\n",
    "def preprocess_images(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for subdir in os.listdir(folder):\n",
    "        subdir_path = os.path.join(folder, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            for file in os.listdir(subdir_path):\n",
    "                file_path = os.path.join(subdir_path, file)\n",
    "                image = Image.open(file_path).convert('L')  # Convertir l'image en niveaux de gris\n",
    "                image = np.array(image).reshape(128, 128, 1)  # Transformer l'image en un tableau 3D\n",
    "                images.append(image)\n",
    "                labels.append(subdir)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ebc4fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 93s 5s/step - loss: 118.1041 - accuracy: 0.2827\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 44s 3s/step - loss: 0.9994 - accuracy: 0.5503\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 96s 6s/step - loss: 0.6649 - accuracy: 0.7666\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 90s 6s/step - loss: 0.4238 - accuracy: 0.8480\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 91s 6s/step - loss: 0.3111 - accuracy: 0.8844\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 88s 6s/step - loss: 0.1998 - accuracy: 0.9208\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 77s 5s/step - loss: 0.1742 - accuracy: 0.9358\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 78s 5s/step - loss: 0.1934 - accuracy: 0.9507\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 78s 5s/step - loss: 0.1593 - accuracy: 0.9443\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 79s 5s/step - loss: 0.1693 - accuracy: 0.9572\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6545 - accuracy: 0.8291\n",
      "Loss: 0.654486358165741\n",
      "Accuracy: 0.8290598392486572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Charger les données\n",
    "X, y = preprocess_images('train')\n",
    "\n",
    "# Encoder les labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Diviser les données en un ensemble d'entraînement et un ensemble de test\n",
    "X_train_CNN, X_test_CNN, y_train_CNN, y_test_CNN = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instancier le modèle\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "model.fit(X_train_CNN, y_train_CNN, epochs=10, batch_size=32)\n",
    "\n",
    "# Évaluer le modèle\n",
    "loss, accuracy = model.evaluate(X_test_CNN, y_test_CNN)\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb14029",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae6422be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Calibrated Linear Discriminant Analysis: 0.8547008547008547\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Instantiate the LinearDiscriminantAnalysis\n",
    "base_model = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Fit the LinearDiscriminantAnalysis\n",
    "base_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make a prediction\n",
    "y_pred = base_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Accuracy Calibrated Linear Discriminant Analysis: {accuracy_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e19e570",
   "metadata": {},
   "source": [
    "# Evaluation du modéle (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2bef158",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 16384, got 128",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(image)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Faire une prédiction\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Obtenir la classe avec la plus grande probabilité\u001b[39;00m\n\u001b[0;32m     20\u001b[0m predicted_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(prediction)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1553\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1545\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1546\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1550\u001b[0m     iteration_range: Optional[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1551\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m-> 1553\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[0;32m   1561\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1168\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1168\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m   1177\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:2428\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2424\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2425\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2426\u001b[0m         )\n\u001b[0;32m   2427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features() \u001b[38;5;241m!=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m-> 2428\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2429\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature shape mismatch, expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2430\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2431\u001b[0m         )\n\u001b[0;32m   2433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_np_array_like(data):\n\u001b[0;32m   2434\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ensure_np_dtype\n",
      "\u001b[1;31mValueError\u001b[0m: Feature shape mismatch, expected: 16384, got 128"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir('./test'):\n",
    "    if filename.endswith('.png'):  # Assurez-vous que le fichier est une image PNG\n",
    "        # Construire le chemin complet du fichier\n",
    "        filepath = os.path.join('./test', filename)\n",
    "\n",
    "        # Charger l'image\n",
    "        image = Image.open(filepath).convert('L')\n",
    "\n",
    "        # Redimensionner l'image pour correspondre à la forme d'entrée du modèle\n",
    "        image = image.resize((128, 128))\n",
    "\n",
    "        # Convertir l'image en un tableau numpy et la remodeler\n",
    "        image = np.array(image).reshape(1, 128, 128, 1)\n",
    "        \n",
    "\n",
    "        # Faire une prédiction\n",
    "        prediction = model.predict(image)\n",
    "\n",
    "        # Obtenir la classe avec la plus grande probabilité\n",
    "        predicted_class = np.argmax(prediction)\n",
    "\n",
    "        # Convertir la classe prédite en son label correspondant\n",
    "        predicted_label = le.inverse_transform([predicted_class])\n",
    "\n",
    "        print(f\"Le modèle prédit que l'image {filename} est un : {predicted_label[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dbe6c7",
   "metadata": {},
   "source": [
    "# Evaluation du modéle (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf7609ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the model to test\n",
    "model = base_model # It's the model for LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2244cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: boat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "labels = [\"airplane\", \"boat\",\"bus\",\"car\"]\n",
    "\n",
    "# Your preprocessing function, modified to process a single image\n",
    "def preprocess_single_image(image_path):\n",
    "    threshold = 128\n",
    "    # Convert the image to grayscale\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    # Flatten the image\n",
    "        # Transformer l'image en un vecteur\n",
    "    image = np.array(image)\n",
    "    image = np.where(image > threshold, 0, 1)  # 0 pour blanc, 1 pour noir\n",
    "    \n",
    "    image.flatten()\n",
    "    return image\n",
    "\n",
    "# Load your trained model\n",
    "\n",
    "# Path to your image\n",
    "image_path = './test/test2.png'  # Update this path\n",
    "\n",
    "# Preprocess the image\n",
    "preprocessed_image = preprocess_single_image(image_path)\n",
    "\n",
    "# Since the model expects a 2D array, reshape the preprocessed image\n",
    "preprocessed_image = preprocessed_image.reshape(1, -1)\n",
    "\n",
    "# Predict the class\n",
    "prediction = model.predict(preprocessed_image)\n",
    "predicted_class = prediction[0]  # Assuming the model returns a list of predictions\n",
    "\n",
    "# Assuming you have the LabelEncoder saved or you know the class names\n",
    "# If you saved your LabelEncoder during training, load it the same way as your model\n",
    "# Otherwise, replace `class_names` with the actual list of class names in the correct order\n",
    "# le = joblib.load('path_to_your_label_encoder.pkl')  # Uncomment if you saved your LabelEncoder\n",
    "# predicted_class_name = le.inverse_transform([predicted_class])[0]  # Uncomment if you saved your LabelEncoder\n",
    "# print(f\"Predicted class: {predicted_class_name}\")  # Uncomment if you saved your LabelEncoder\n",
    "\n",
    "print(f\"Predicted class: {labels[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6f6401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class for the image test1.png is: bus\n",
      "The predicted class for the image test2.png is: boat\n",
      "The predicted class for the image test3.png is: car\n",
      "The predicted class for the image test4.png is: airplane\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    threshold = 128\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    image = Image.open(image_path).convert('L')  \n",
    "    # Transformer l'image en un vecteur\n",
    "    image = np.array(image)\n",
    "    image = np.where(image > threshold, 0, 1)  # 0 pour blanc, 1 pour noir\n",
    "    \n",
    "    image.flatten()\n",
    "    # Turn categorical data into numerical values\n",
    "    \n",
    "    return np.array(image)\n",
    "\n",
    "labels = [\"airplane\",\"boat\",\"bus\",\"car\"]\n",
    "\n",
    "root_dir = \"./test\"\n",
    "for filename in os.listdir(root_dir):\n",
    "    if filename.endswith('.png'):  # Ensure the file is a PNG image\n",
    "        # Construct the full file path\n",
    "        filepath = os.path.join(root_dir, filename)\n",
    "        # Preprocess the image\n",
    "        image = preprocess_image(filepath)\n",
    "        # Reshape the image data to match the input shape of the model\n",
    "        image = image.reshape(1, -1)\n",
    "\n",
    "        # Make a prediction\n",
    "        prediction = model.predict(image)\n",
    "\n",
    "        print(f\"The predicted class for the image {filename} is: {labels[prediction[0]]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e793b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79cfdfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
